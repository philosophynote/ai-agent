{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201fb5c6-00ec-412a-8af9-2ca43de576f6",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/agents/#setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870915f-dc77-4d5c-9eb5-4ca2b089589e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain-community langgraph langchain_openai tavily-python langgraph-checkpoint-sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0769f76f-ed47-4a17-b09c-6c8978a8bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e81238-5af3-43bd-90e8-8c763374f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17dbc9-b0d2-496c-b25b-dc492c979da1",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e225448-d0a3-4d0a-bdf9-fe3921b5404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81dd9b2c-7de6-4b58-aa75-e449d75cb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969fea1-6edf-460e-8e11-22471f2bf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"フェルマーの最終定理について解説して\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc4086-6ff7-4e77-8459-dd238454d52c",
   "metadata": {},
   "source": [
    "We can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools\n",
    "\n",
    "このモデルでツールを呼び出せるようにするにはどうすればいいか、見てみよう。 それを可能にするために、.bind_toolsを使い、言語モデルにこれらのツールに関する知識を与えている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64221d0e-4ef7-4f97-ada9-56228d5800de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51b1c2-f7b6-48db-8059-ca5c29cc8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73bcd2-39f0-467d-b7b2-a38e248255be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6172ae-fe66-4a72-b768-57897f2ab60a",
   "metadata": {},
   "source": [
    "### エージェントの作成 \n",
    "\n",
    "ツールとLLMを定義したので、エージェントを作成します。 \n",
    "エージェントの作成にはLangGraphを使います。 \n",
    "現在のところ、エージェントを構築するために高レベルのインタフェースを使用していますが、\n",
    "LangGraphの良いところは、この高レベルのインタフェースが、エージェントのロジックを変更したい場合に備えて、\n",
    "低レベルで高度に制御可能なAPIに支えられていることです。 \n",
    "\n",
    "さて、LLMとツールでエージェントを初期化しましょう。 \n",
    "model_with_toolsではなく、modelを渡していることに注意してください。 \n",
    "これは、create_react_agent が .bind_tools を呼び出すからです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5698be-95f0-4372-a891-d07b65853f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584ac26-6385-4032-a760-dbfcd5e8b682",
   "metadata": {},
   "source": [
    "### エージェントの実行 \n",
    "\n",
    "いくつかのクエリでエージェントを実行することができます！ \n",
    "今のところ、これらはすべてステートレスクエリであることに注意してください（以前のやりとりを覚えていません）。 \n",
    "エージェントはインタラクションの最後に最終的な状態を返すことに注意してください\n",
    "（これはあらゆる入力を含みますが、出力だけを取得する方法は後で説明します）。 \n",
    "\n",
    "まず最初に、ツールを呼び出す必要がないときにどのように応答するかを見てみましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f851a3-b249-4ca0-9a0d-3b5b07ebd5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfbb26b-57d2-48ee-8ec5-bc9cac0689d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfecd80-9d73-485c-88c4-db6701870548",
   "metadata": {},
   "source": [
    "メッセージのストリーミング \n",
    "\n",
    "エージェントを.invokeで呼び出して、最終的なレスポンスを返す方法について見てきました。 \n",
    "エージェントが複数のステップを実行する場合、時間がかかるかもしれません。 \n",
    "途中経過を表示するために、発生したメッセージをストリームバックすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be972d59-7ce8-46a2-86e4-ae7693d371b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"株式会社hogeの評判について教えてください\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdc89b-280b-4003-aaea-71bbd9189c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for event in agent_executor.astream_events(\n",
    "    {\"messages\": [HumanMessage(content=\"株式会社hogeの評判について教えてください\")]}, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"Agent\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d18ad-3117-4cdb-9918-c6d68e27a46a",
   "metadata": {},
   "source": [
    "メモリーへの追加 \n",
    "\n",
    "前述のように、このエージェントはステートレスである。 \n",
    "つまり、以前のやりとりを覚えていない。 \n",
    "記憶させるためには、チェックポインタを渡す必要がある。 \n",
    "チェックポインタを渡すとき、\n",
    "エージェントを起動するときにスレッドIDも渡す必要があります\n",
    "（どのスレッド/会話から再開するかを知るため）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e5edad2-10c0-47cf-8905-90e99680b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ba85ef3-6ef5-4fc0-9136-ec75ee6d1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef4eb0-8bde-419b-bb78-539db3e58426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im naoki!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69267877-7a43-4cab-9ff4-f2d73e236d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5d7b5-5f79-4c1d-a493-d1b2821575ab",
   "metadata": {},
   "source": [
    "まとめ \n",
    "\n",
    "以上です！ \n",
    "このクイックスタートでは、シンプルなエージェントの作成方法を説明しました。 \n",
    "\n",
    "そして、中間ステップだけでなく、トークンも含めてレスポンスをストリームバックする方法を示しました！ \n",
    "\n",
    "さらに、エージェントと会話ができるようにメモリも追加しました。 \n",
    "エージェントは複雑なトピックで、学ぶことがたくさんあります！\n",
    "エージェントに関する詳しい情報は、LangGraphのドキュメントをご覧ください。 \n",
    "\n",
    "これには独自のコンセプト、チュートリアル、ハウツーガイドがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119af1f-cb4a-477c-a88b-df4874a25af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
