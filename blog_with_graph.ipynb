{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f519ae33-f016-4640-a20b-595b43e3cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from collections.abc import Sequence\n",
    "from typing import Annotated, TypedDict, Literal, Any, Callable\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    ChatMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage\n",
    ")\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f839d",
   "metadata": {},
   "source": [
    "https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/?h=router#router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0728df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_router(state: AgentState) -> Literal[\"Writer\", \"continue\", \"call_tool\", \"__end__\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"call_tool\"\n",
    "\n",
    "    if isinstance(last_message, AIMessage):\n",
    "        if last_message.name == \"Reviewer\":\n",
    "            content = last_message.content.lower()\n",
    "            score_match = re.search(r\"総合評価:\\s*(\\d+)\", content, re.IGNORECASE)\n",
    "            if score_match:\n",
    "                try:\n",
    "                    score = int(score_match.group(1))\n",
    "                    if score >= 8:\n",
    "                        return \"__end__\"\n",
    "                except ValueError:\n",
    "                    print(f\"警告: スコアの解析に失敗しました。内容: {content}\")\n",
    "            else:\n",
    "                print(f\"警告: スコアが見つかりませんでした。内容: {content}\")\n",
    "            return \"continue\"\n",
    "\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b8ba6",
   "metadata": {},
   "source": [
    "Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dd3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class AgentNode:\n",
    "    def __init__(\n",
    "        self, name: str, llm: ChatOpenAI, tools: list[Callable], system_message: str\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.agent = self._create_agent(llm, tools, system_message)\n",
    "        self.tool_used = False  # ツール使用フラグを追加\n",
    "        self.llm = llm\n",
    "        self.system_message = system_message\n",
    "\n",
    "    def __call__(self, state: AgentState) -> Any:\n",
    "        if self.tool_used:\n",
    "            result = self._create_agent(self.llm, [], self.system_message).invoke(state)\n",
    "        else:\n",
    "            result = self.agent.invoke(state)\n",
    "        if not isinstance(result, ToolMessage):\n",
    "            result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=self.name)\n",
    "            self.tool_used = True\n",
    "\n",
    "        self.save_output(result.content)\n",
    "\n",
    "        return {\n",
    "            \"messages\": [result],\n",
    "            \"sender\": self.name,\n",
    "        }\n",
    "\n",
    "    def save_output(self, content: str) -> None:\n",
    "        timemin = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = Path(\"outputs\") / timemin / f\"{self.name}_{timestamp}.txt\"\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if len(content) > 100:\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "            print(f\"Output saved to {filename}\")\n",
    "\n",
    "    def _create_agent(\n",
    "        self, llm: ChatOpenAI, tools: list[Callable], system_message: str\n",
    "    ) -> RunnableLambda[Any, Any]:\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"あなたは他の助手と協力する役立つAIアシスタントです。\"\n",
    "                    \"提供されたツールを使用して、質問に答えるための進展を図ってください。\"\n",
    "                    \"完全に回答できない場合でも問題ありません。別のツールを持つ他の助手が、あなたが中断したところから引き継いで支援します。\"\n",
    "                    \"進展を図るために、できることを実行してください。\"\n",
    "                    \"あなたは以下のツールにアクセスできます：{tool_names}。\\n{system_message}\",\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            ]\n",
    "        )\n",
    "        prompt = prompt.partial(system_message=system_message)\n",
    "\n",
    "        if tools:\n",
    "            prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "            return prompt | llm.bind_tools(tools)\n",
    "\n",
    "        prompt = prompt.partial(tool_names=\"なし\")\n",
    "        return prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f81d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_write_blog_workflow(\n",
    "    agent_state: type[Any],\n",
    "    router: Callable,\n",
    "    write_node: AgentNode,\n",
    "    review_node: AgentNode,\n",
    "    tool_node: ToolNode,\n",
    ") -> CompiledStateGraph:\n",
    "    workflow = StateGraph(agent_state)\n",
    "    tool_name: str = tool_node.name  # type: ignore\n",
    "    workflow.add_node(write_node.name, write_node)\n",
    "    workflow.add_node(review_node.name, review_node)\n",
    "    workflow.add_node(tool_name, tool_node)\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        write_node.name,\n",
    "        router,\n",
    "        {\"continue\": review_node.name, tool_name: tool_name, END: END},\n",
    "    )\n",
    "    workflow.add_conditional_edges(\n",
    "        review_node.name,\n",
    "        router,\n",
    "        {\"continue\": write_node.name, END: END},\n",
    "    )\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"call_tool\",\n",
    "        lambda x: x[\"sender\"],\n",
    "        {\n",
    "            write_node.name: write_node.name,\n",
    "            review_node.name: review_node.name,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(START, write_node.name)\n",
    "    graph = workflow.compile()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57988c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_config = OmegaConf.load('writer.yaml')\n",
    "reviewer_config = OmegaConf.load('reviewer.yaml')\n",
    "writer_config = OmegaConf.to_container(writer_config, resolve=True)\n",
    "reviewer_config = OmegaConf.to_container(reviewer_config, resolve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4fec4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b203b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o-mini\")\n",
    "search = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60cbbdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_messages = writer_config['messages']\n",
    "\n",
    "writer_prompt_messages = []\n",
    "\n",
    "for message in writer_messages:\n",
    "    role, content = message\n",
    "    if role == 'system':\n",
    "        writer_prompt_messages.append(SystemMessagePromptTemplate.from_template(content))\n",
    "    elif role == 'human':\n",
    "        writer_prompt_messages.append(HumanMessagePromptTemplate.from_template(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6917b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_messages = reviewer_config['messages']\n",
    "\n",
    "reviewer_prompt_messages = []\n",
    "\n",
    "for message in reviewer_messages:\n",
    "    role, content = message\n",
    "    if role == 'system':\n",
    "        reviewer_prompt_messages.append(SystemMessagePromptTemplate.from_template(content))\n",
    "    elif role == 'human':\n",
    "        reviewer_prompt_messages.append(HumanMessagePromptTemplate.from_template(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc34e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = AgentNode(\"Writer\", llm, [search], writer_prompt_messages)\n",
    "reviewer_agent = AgentNode(\"Writer\", llm, [search], reviewer_prompt_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_write_blog_workflow(AgentState, review_router(writer_config), writer_agent, reviewer_agent, search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdcbc7",
   "metadata": {},
   "source": [
    "https://langchain-ai.github.io/langgraph/tutorials/introduction/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
